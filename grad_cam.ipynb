{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "grad_cam.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8R-Oo1T8m507",
        "outputId": "48600531-86b8-4683-b4ee-07f5d3b0303b"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting grad-cam\n",
            "  Downloading grad-cam-1.3.7.tar.gz (4.5 MB)\n",
            "\u001b[K     |████████████████████████████████| 4.5 MB 5.1 MB/s \n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n",
            "  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n",
            "    Preparing wheel metadata ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.64.0)\n",
            "Requirement already satisfied: opencv-python in /usr/local/lib/python3.7/dist-packages (from grad-cam) (4.1.2.30)\n",
            "Requirement already satisfied: torchvision>=0.8.2 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (0.12.0+cu113)\n",
            "Requirement already satisfied: torch>=1.7.1 in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.11.0+cu113)\n",
            "Requirement already satisfied: Pillow in /usr/local/lib/python3.7/dist-packages (from grad-cam) (7.1.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from grad-cam) (1.21.6)\n",
            "Collecting ttach\n",
            "  Downloading ttach-0.0.3-py3-none-any.whl (9.8 kB)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch>=1.7.1->grad-cam) (4.2.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision>=0.8.2->grad-cam) (2.23.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision>=0.8.2->grad-cam) (2.10)\n",
            "Building wheels for collected packages: grad-cam\n",
            "  Building wheel for grad-cam (PEP 517) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for grad-cam: filename=grad_cam-1.3.7-py3-none-any.whl size=25953 sha256=67b0381aeade072927fe17d6d055c8fe86d327dde81e3c402890792730b2805d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/ab/9c/53c523785edffdc6c61755cf82e0dac3342d0d36190c187894\n",
            "Successfully built grad-cam\n",
            "Installing collected packages: ttach, grad-cam\n",
            "Successfully installed grad-cam-1.3.7 ttach-0.0.3\n",
            "Mounted at /content/drive\n",
            "/content/drive/My Drive/Br35H-Mask-RCNN\n"
          ]
        }
      ],
      "source": [
        "!pip install grad-cam\n",
        "root_folder = '/content/drive/My Drive/Br35H-Mask-RCNN'\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "%cd \"/content/drive/My Drive/Br35H-Mask-RCNN\""
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM, FullGrad\n",
        "from pytorch_grad_cam.utils.model_targets import ClassifierOutputTarget\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image\n",
        "from torchvision.models import resnet50, vgg16\n",
        "import torch\n",
        "from pytorch_grad_cam.utils.image import show_cam_on_image, deprocess_image, preprocess_image\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from PIL import Image\n",
        "\n",
        "!pip install pretrainedmodels\n",
        "import pretrainedmodels\n",
        "\n",
        "import torch\n",
        "from torch import nn, optim\n",
        "import torchvision\n",
        "from torch.nn import functional as F\n",
        "\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "\n",
        "import os\n",
        "import torch\n",
        "import pandas as pd\n",
        "from skimage import io, transform\n",
        "\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, utils\n",
        "import cv2\n",
        "from PIL import Image\n",
        "import glob\n",
        "from scipy.ndimage import gaussian_filter\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3rPtzZEDnLqw",
        "outputId": "dfa17f08-c4c2-496f-d57d-ff91cbec5413"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting pretrainedmodels\n",
            "  Downloading pretrainedmodels-0.7.4.tar.gz (58 kB)\n",
            "\u001b[?25l\r\u001b[K     |█████▋                          | 10 kB 2.2 MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 20 kB 3.8 MB/s eta 0:00:01\r\u001b[K     |████████████████▊               | 30 kB 4.9 MB/s eta 0:00:01\r\u001b[K     |██████████████████████▎         | 40 kB 6.3 MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▉    | 51 kB 5.3 MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 58 kB 2.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: torch in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (1.11.0+cu113)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (0.12.0+cu113)\n",
            "Collecting munch\n",
            "  Downloading munch-2.5.0-py2.py3-none-any.whl (10 kB)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.7/dist-packages (from pretrainedmodels) (4.64.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.7/dist-packages (from munch->pretrainedmodels) (1.15.0)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torch->pretrainedmodels) (4.2.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (7.1.2)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (2.23.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from torchvision->pretrainedmodels) (1.21.6)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (3.0.4)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (2021.10.8)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.7/dist-packages (from requests->torchvision->pretrainedmodels) (1.24.3)\n",
            "Building wheels for collected packages: pretrainedmodels\n",
            "  Building wheel for pretrainedmodels (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pretrainedmodels: filename=pretrainedmodels-0.7.4-py3-none-any.whl size=60965 sha256=c1a60bfde6bb3bf02710a19d39b9dc736eb9434a347d28fed7bcdb7b41f7d1e5\n",
            "  Stored in directory: /root/.cache/pip/wheels/ed/27/e8/9543d42de2740d3544db96aefef63bda3f2c1761b3334f4873\n",
            "Successfully built pretrainedmodels\n",
            "Installing collected packages: munch, pretrainedmodels\n",
            "Successfully installed munch-2.5.0 pretrainedmodels-0.7.4\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Generate Class activation Map for data\n"
      ],
      "metadata": {
        "id": "_0OHsO7NahIK"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Train CAM"
      ],
      "metadata": {
        "id": "f48_seWJZE3E"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "\n",
        "dump_model = vgg16(pretrained=True)\n",
        "dump_target_layers = [dump_model.features[-1]] \n",
        "dump_process = transforms.Compose([transforms.ToTensor(),\n",
        "                                    # transforms.Resize((128, 128)),\n",
        "                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "with EigenCAM(model=dump_model, target_layers=dump_target_layers) as dump_cam:\n",
        "  for i in range (500):\n",
        "    image_path = os.path.join (root_folder,\"TRAIN_ANNOT/y\" + str(i) + \".png\" )\n",
        "    dump_img =Image.open(image_path)\n",
        "    dump_input_tensor = torch.unsqueeze(dump_process(dump_img), 0)\n",
        "    dump_grayscale_cam = dump_cam(input_tensor=dump_input_tensor, targets=None)[0, :]\n",
        "    save_path = os.path.join(root_folder,\"T_CAM/y\" + str(i) + \".npy\")\n",
        "    np.save(save_path, dump_grayscale_cam)"
      ],
      "metadata": {
        "id": "506T1rmV1L36"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Validation CAM"
      ],
      "metadata": {
        "id": "mPrS3_PJkjB5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dump_model = vgg16(pretrained=True)\n",
        "dump_target_layers = [dump_model.features[-1]] \n",
        "dump_process = transforms.Compose([transforms.ToTensor(),\n",
        "                                    # transforms.Resize((128, 128)),\n",
        "                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "with EigenCAM(model=dump_model, target_layers=dump_target_layers) as dump_cam:\n",
        "  for i in range (700, 701):\n",
        "    image_path = os.path.join (root_folder,\"VAL_ANNOT/y\" + str(i) + \".png\" )\n",
        "    dump_img =Image.open(image_path)\n",
        "    \n",
        "    dump_input_tensor = torch.unsqueeze(dump_process(dump_img), 0)\n",
        "    dump_grayscale_cam = dump_cam(input_tensor=dump_input_tensor, targets=None)[0, :]\n",
        "\n",
        "    save_path = os.path.join(root_folder,\"V_CAM/y\" + str(i) + \".npy\")\n",
        "    np.save(save_path, dump_grayscale_cam)"
      ],
      "metadata": {
        "id": "IILquEUhknj_"
      },
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Test CAM"
      ],
      "metadata": {
        "id": "Z9fXQJO51YBg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dump_model = vgg16(pretrained=True)\n",
        "dump_target_layers = [dump_model.features[-1]] \n",
        "dump_process = transforms.Compose([transforms.ToTensor(),\n",
        "                                    # transforms.Resize((128, 128)),\n",
        "                                    transforms.Normalize((0.485, 0.456, 0.406), (0.229, 0.224, 0.225))])\n",
        "\n",
        "with EigenCAM(model=dump_model, target_layers=dump_target_layers) as dump_cam:\n",
        "  for i in range (700, 701):\n",
        "    image_path = os.path.join (root_folder,\"TEST_ANNOT/y\" + str(i) + \".png\" )\n",
        "    dump_img =Image.open(image_path)\n",
        "    dump_input_tensor = torch.unsqueeze(dump_process(dump_img), 0)\n",
        "    dump_grayscale_cam = dump_cam(input_tensor=dump_input_tensor, targets=None)[0, :]\n",
        "\n",
        "    save_path = os.path.join(root_folder,\"TEST_CAM/y\" + str(i) + \".npy\")\n",
        "    np.save(save_path, dump_grayscale_cam)"
      ],
      "metadata": {
        "id": "ktJD8je_1Zxh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Display one cam example"
      ],
      "metadata": {
        "id": "3TTtMSJUNI_J"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "img_array = np.load(os.path.join(root_folder,'T_CAM/y30.npy'))\n",
        "from matplotlib import pyplot as plt\n",
        "\n",
        "plt.imshow(img_array, cmap='gray')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "lCTdHCQno2Gb",
        "outputId": "bca9070f-b7b3-43e5-db36-b97f4ef3944e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    }
  ]
}